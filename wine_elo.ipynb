{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python392jvsc74a57bd0767d51c1340bd893661ea55ea3124f6de3c7a262a8b4abca0554b478b1e2ff90",
   "display_name": "Python 3.9.2 64-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "767d51c1340bd893661ea55ea3124f6de3c7a262a8b4abca0554b478b1e2ff90"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "import datetime\n",
    "from dateutil.relativedelta import relativedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for f in os.listdir('raw_data'):\n",
    "#     filename = 'raw_data/' + f\n",
    "#     with open(filename, 'r') as contents:\n",
    "#         wine_reviews = json.loads(contents)\n",
    "\n",
    "with open('raw_data/4057966.json') as filepath:\n",
    "    wine_reviews = json.loads(filepath.read())\n",
    "\n",
    "wine_review_df = pd.json_normalize(wine_reviews)\n",
    "scrape_date_unix = os.path.getmtime('raw_data/4057966.json')\n",
    "scrape_date = datetime.datetime.fromtimestamp(scrape_date_unix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nearest(items, pivot):\n",
    "    return min(items, key=lambda x: abs(x - pivot))\n",
    "\n",
    "\n",
    "def compute_date(scrape_date, review_date, review_time_ago):\n",
    "    review_month = review_date[5:8]\n",
    "    review_day = review_date[-20:-18].strip()\n",
    "\n",
    "    if 'over' in review_time_ago:\n",
    "        crop_offset_string = review_time_ago.split('over')[1].strip()\n",
    "        offset_period = int(crop_offset_string[:2].strip())\n",
    "\n",
    "        min_date = scrape_date - relativedelta(months=12*(offset_period+1))\n",
    "        max_date = scrape_date - relativedelta(months=12*offset_period)\n",
    "\n",
    "        candidate_years = [min_date.year, max_date.year]\n",
    "        candidate_dates = [datetime.datetime.strptime(review_day + ' ' + review_month + ' ' + str(y), '%d %b %Y') for y in candidate_years]\n",
    "\n",
    "        final_review_date = [d for d in candidate_dates if d > min_date and d < max_date][0]\n",
    "\n",
    "    elif 'almost' in review_time_ago:\n",
    "        crop_offset_string = review_time_ago.split('almost')[1].strip()\n",
    "        offset_period = int(crop_offset_string[:2].strip())\n",
    "\n",
    "        min_date = scrape_date - relativedelta(months=12*offset_period)\n",
    "        max_date = scrape_date\n",
    "\n",
    "        candidate_years = [min_date.year, max_date.year]\n",
    "        candidate_dates = [datetime.datetime.strptime(review_day + ' ' + review_month + ' ' + str(y), '%d %b %Y') for y in candidate_years]\n",
    "\n",
    "        final_review_date = [d for d in candidate_dates if d > min_date and d < max_date][0]      \n",
    "\n",
    "    else:\n",
    "        if 'about' in review_time_ago:\n",
    "            crop_offset_string = review_time_ago.split('about')[1].strip()\n",
    "            offset_period = int(crop_offset_string[:2].strip())\n",
    "        else:\n",
    "            offset_period = int(review_time_ago[:2].strip())\n",
    "\n",
    "        if 'month' in review_time_ago:\n",
    "            offset_scrape_date = scrape_date - relativedelta(months=offset_period)\n",
    "        elif 'year' in review_time_ago:\n",
    "            offset_scrape_date = scrape_date - relativedelta(months=12*offset_period)\n",
    "        else:\n",
    "            offset_scrape_date = scrape_date\n",
    "        \n",
    "        candidate_years = [offset_scrape_date.year - 1, offset_scrape_date.year, offset_scrape_date.year + 1]\n",
    "        try:\n",
    "            candidate_dates = [datetime.datetime.strptime(review_day + ' ' + review_month + ' ' + str(y), '%d %b %Y') for y in candidate_years]\n",
    "        # in some fringe cases, we may be dealing with February 29th, which only exists on leap years\n",
    "        except ValueError:\n",
    "            candidate_dates = [datetime.datetime.strptime(str(int(review_day) - 1) + ' ' + review_month + ' ' + str(y), '%d %b %Y') for y in candidate_years]\n",
    "        \n",
    "        final_review_date = nearest(candidate_dates, offset_scrape_date)\n",
    "    \n",
    "    return final_review_date\n",
    "\n",
    "\n",
    "# function to create a compound ID that uniquely identifies a wine by its vintage, review year \n",
    "def create_wine_year_id(wine_id, vintage, review_year):\n",
    "    compound_id = str(wine_id) + '-' + str(vintage) + '-' + str(review_year)\n",
    "    return compound_id\n",
    "\n",
    "\n",
    "def clean_wine_reviews(review_df):\n",
    "    review_df['final_review_date'] = review_df.apply(lambda x: compute_date(scrape_date, x['review_date'], x['review_time_ago']), axis=1)\n",
    "    review_df['review_year'] = review_df['final_review_date'].apply(lambda x: x.year)\n",
    "\n",
    "    # drop any reviews that don't have a vintage specified. N.V. is acceptable, but blank vintage is not. \n",
    "    review_df['vintage'].replace({'': np.nan}, inplace=True)\n",
    "    review_df.dropna(subset=['vintage'], axis=0, inplace=True)\n",
    "\n",
    "    review_df['wine_year_id'] = review_df.apply(lambda x: create_wine_year_id(x['wine_id'], x['vintage'], x['review_year']), axis=1)\n",
    "\n",
    "    just_reviews = review_df[['wine_year_id',  'review_year', 'wine_id', 'rating', 'final_review_date']]\n",
    "    return just_reviews\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "              wine_id_0            wine_id_1               result       date\n0   128488603-2014-2016    6005359-2013-2016  128488603-2014-2016 2016-05-24\n1   128488603-2014-2016  152865445-2014-2016  128488603-2014-2016 2016-05-24\n2     6005359-2013-2016  152865445-2014-2016    6005359-2013-2016 2016-05-24\n3     1461803-2011-2019    2902509-2005-2019    2902509-2005-2019 2019-06-26\n4     1461803-2011-2019  152489457-2017-2019  152489457-2017-2019 2019-06-26\n5     2902509-2005-2019  152489457-2017-2019  152489457-2017-2019 2019-06-26\n6     2273741-2012-2014    4342756-2012-2014                  NaN 2014-08-30\n7     7758438-2013-2015    3482061-2012-2015                  NaN 2015-12-06\n8     7758438-2013-2015    1239962-2011-2015    1239962-2011-2015 2015-12-06\n9     7758438-2013-2015    4172365-2012-2015    4172365-2012-2015 2015-12-06\n10    7758438-2013-2015   23097634-2014-2015   23097634-2014-2015 2015-12-06\n11    3482061-2012-2015    1239962-2011-2015    1239962-2011-2015 2015-12-06\n12    3482061-2012-2015    4172365-2012-2015    4172365-2012-2015 2015-12-06\n13    3482061-2012-2015   23097634-2014-2015   23097634-2014-2015 2015-12-06\n14    1239962-2011-2015    4172365-2012-2015    1239962-2011-2015 2015-12-06\n15    1239962-2011-2015   23097634-2014-2015    1239962-2011-2015 2015-12-06\n16    4172365-2012-2015   23097634-2014-2015                  NaN 2015-12-06\n17    4439874-2013-2015    2552539-2011-2015    2552539-2011-2015 2015-07-27\n18    3468542-2011-2015   10090548-2007-2015   10090548-2007-2015 2015-03-11\n19  110725063-2015-2017  152792053-2016-2017  152792053-2016-2017 2017-11-13\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from itertools import combinations\n",
    "\n",
    "wine_reviews = clean_wine_reviews(wine_review_df)\n",
    "wine_reviews = wine_reviews.set_index(['wine_year_id'])\n",
    "\n",
    "def compute_head_to_head_result(wine_0, wine_1, rating_0, rating_1):\n",
    "    if rating_0 > rating_1:\n",
    "        return wine_0\n",
    "    elif rating_0 < rating_1:\n",
    "        return wine_1\n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "\n",
    "def elo_transform(review_df):\n",
    "    review_years = list(set(review_df['final_review_date']))\n",
    "    head_to_heads = []\n",
    "    for r in review_years:\n",
    "        review_df_slice = review_df.loc[review_df['final_review_date'] == r]\n",
    "        # in case there are duplicate reviews of a wine within a given year, only keep the first one\n",
    "        review_df_slice = review_df_slice.sort_values(by='final_review_date')\n",
    "        review_df_slice = review_df_slice.reset_index().drop_duplicates(subset='wine_year_id', keep='first').set_index('wine_year_id')\n",
    "        combo = list(combinations(review_df_slice.index, 2))\n",
    "        for c in combo:\n",
    "            rating_0 = review_df_slice.at[c[0], 'rating']\n",
    "            rating_1 = review_df_slice.at[c[1], 'rating']\n",
    "            result = compute_head_to_head_result(c[0], c[1], rating_0, rating_1)\n",
    "            date_0 = review_df_slice.at[c[0], 'final_review_date']\n",
    "            date_1 = review_df_slice.at[c[1], 'final_review_date']\n",
    "            head_to_head_date = max([date_0, date_1])\n",
    "\n",
    "            output = [c[0], c[1], result, head_to_head_date]\n",
    "\n",
    "            head_to_heads.append(output)\n",
    "    \n",
    "    return head_to_heads\n",
    "\n",
    "results = pd.DataFrame(elo_transform(wine_reviews), columns=['wine_id_0', 'wine_id_1', 'result', 'date'])\n",
    "print(results.head(20))"
   ]
  }
 ]
}